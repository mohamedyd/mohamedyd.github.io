@INPROCEEDINGS{ALKS25a, 
author={Mohamed Abdelaal and Samuel Lokadja and Arne Kreuz and Harald Schoening}, 
booktitle={28th International Conference on Extending Database Technology (EDBT)}, 
title={DataLens: Interactive ML-Oriented Tabular Data Quality Dashboard},
year={2025},
abstract={Maintaining high data quality is crucial for reliable data analysis and machine learning (ML). However, existing data quality management tools often lack automation, interactivity, and integration with ML workflows. This demonstration paper introduces DataLens, a novel interactive dashboard designed to streamline and automate the data quality management process for tabular data. DataLens integrates a suite of data profiling, error detection, and re- pair tools, including statistical, rule-based, and ML-based methods. It features a user-in-the-loop module for interactive rule validation, data labeling, and custom rule definition, enabling domain experts to guide the cleaning process. Furthermore, DataLens implements an iterative cleaning module that automatically selects optimal cleaning tools based on downstream ML model performance. To ensure reproducibility, DataLens generates DataSheets capturing essential metadata and integrates with MLflow and Delta Lake for experiment tracking and data version control. This demonstration showcases DataLens's capabilities in effectively identifying and correcting data errors, improving data quality for downstream tasks, and promoting reproducibility in data cleaning pipelines.},
bibtex_show={true},
preview={under_review.png},}

@INPROCEEDINGS{ALE25b, 
author={Mohamed Abdelaal and Samuel Lokadjaja and Gilbert Engert}, 
booktitle={21st Conference on Database Systems for Business, Technology and Web (BTW)}, 
title={GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback},
year={2025},
abstract={This paper introduces GLLM, an innovative tool that leverages Large Language Models (LLMs) to automatically generate G-code from natural language instructions for Computer Numerical Control (CNC) machining. GLLM addresses the challenges of manual G-code writing by bridging the gap between human-readable task descriptions and machine-executable code. The system incorporates a fine-tuned StarCoder-3B model, enhanced with domain-specific training data and a Retrieval- Augmented Generation (RAG) mechanism. GLLM employs advanced prompting strategies and a novel self-corrective code generation approach to ensure both syntactic and semantic correctness of the generated G-code. The architecture includes robust validation mechanisms, including syntax checks, G-code-specific verifications, and functional correctness evaluations using Hausdorff distance. By combining these techniques, GLLM aims to democratize CNC programming, making it more accessible to users without extensive programming experience while maintaining high accuracy and reliability in G-code generation.},
bibtex_show={true},
preview={under_review.png},}

@INPROCEEDINGS{CGA25b, 
author={Kanishk Chaturvedi and Johannes Gasthuber and Mohamed Abdelaal}, 
booktitle={21st Conference on Database Systems for Business, Technology and Web (BTW)}, 
title={EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection},
year={2025},
abstract={This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and thin-edge.io for deploying and managing machine learning models on resource-constrained edge devices. We address the challenges of model optimization, deployment, and lifecycle management in edge environments. The framework's efficacy is demonstrated through a visual quality inspection (VQI) use case where images of assets are processed on edge devices, enabling real-time condition updates within an asset management system. Furthermore, we evaluate the performance benefits of different quantization methods, specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating significant inference time reductions compared to FP32 precision. Our results highlight the potential of EdgeMLOps to enable efficient and scalable AI deployments at the edge for industrial applications},
bibtex_show={true},
preview={under_review.png},}

@INPROCEEDINGS{MAS2024,
  title={Open-Source Drift Detection Tools in Action: Insights from Two Use Cases},
  author={Rieke M{\"u}ller and Mohamed Abdelaal and Davor Stjelja},
  booktitle={International Conference on Big Data Analytics and Knowledge Discovery (DAWAK 2024)},
  year = {2024},
  month={08},
  selected={false},
  bibtex_show={true},
  preview={dawak.jpg},
  pdf={https://arxiv.org/pdf/2404.18673},
  abstract={Data drifts pose a critical challenge in the lifecycle of machine learning (ML) models, affecting their performance and reliability. In response to this challenge, we present a microbenchmark study, called D3Bench, which evaluates the efficacy of open-source drift detection tools. D3Bench examines the capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world data from two smart building use cases.We prioritize assessing the functional suitability of these tools to identify and analyze data drifts. Furthermore, we consider a comprehensive set of non-functional criteria, such as the integrability with ML pipelines, the adaptability to diverse data types, user-friendliness, computational efficiency, and resource demands. Our findings reveal that Evidently AI stands out for its general data drift detection, whereas NannyML excels at pinpointing the precise timing of shifts and evaluating their consequent effects on predictive accuracy.},
}

@INPROCEEDINGS{BAG2024,
  title={LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs},
  author={Fabian Biester and Mohamed Abdelaal and Daniel Del Gaudio},
  booktitle={The 28th European Conference on Advances in Databases and Information Systems (ADBIS)},
  year = {2024},
  selected={false},
  bibtex_show={true},
  preview={adbis.jpg},
  pdf={https://arxiv.org/pdf/2404.18681},
  abstract={Machine learning's influence is expanding rapidly, now integral to decision-making processes from corporate strategy to the advancements in Industry 4.0. The efficacy of Artificial Intelligence broadly hinges on the caliber of data used during its training phase; optimal performance is tied to exceptional data quality. Data cleaning tools, particularly those that exploit functional dependencies within ontological frameworks or context models, are instrumental in augmenting data quality. Nevertheless, crafting these context models is a demanding task, both in terms of resources and expertise, often necessitating specialized knowledge from domain experts. In light of these challenges, this paper introduces an innovative approach, called LLMClean, for the automated generation of context models, utilizing Large Language Models to analyze and understand various datasets. LLMClean encompasses a sequence of actions, starting with categorizing the dataset, extracting or mapping relevant models, and ultimately synthesizing the context model. To demonstrate its potential, we have developed and tested a prototype that applies our approach to three distinct datasets from the Internet of Things, healthcare, and Industry 4.0 sectors. The results of our evaluation indicate that our automated approach can achieve data cleaning efficacy comparable with that of context models crafted by human experts.},
}

@INPROCEEDINGS{RAB24, 
author={Eduardo Reis and Mohamed Abdelaal and Carsten Binnig}, 
booktitle={International Conference on Very Large Data Bases (VLDB)}, 
title={Generalizable Data Cleaning of Tabular Data in Latent Space},
year={2025},
bibtex_show={true},
selected={true},
abstract={In this paper, we present a new method for learned data cleaning. In contrast to existing methods, our method learns to clean data in the latent space. The main idea is that we (1) shape the latent space such that we know the area where clean data resides and (2) learn latent operators trained on error repair (Lopster) which shift erroneous data (e.g., table rows with noise, outliers, or missing values) in their latent representation back to a “clean” region, thus abstracting the complexities of the input domain. When formulating data cleaning as a simple shift operation in latent space, we can repair all types of errors using the same method which makes it more robust than other methods. Importantly, with our method, we can handle errors that are unseen during the training of our error repair model. We do not rely on an external error detection method as seen in the state-of-the-art, instead, we handle both detection and repair within the Lopster framework. In our evaluation, we show that our approach outperforms existing cleaning methods even when trained on only a subset of the errors that occur in the dirty data.},
preview={vldb2025_logo.png}}

@INPROCEEDINGS{abdelaalreclean,
  title={ReClean: Reinforcement Learning for Automated Data Cleaning in ML Pipelines},
  author={Abdelaal, Mohamed and Yayak, Anil Bora and Klede, Kai and Sch{\"o}ning, Harald},
  booktitle={International Workshop on Databases and Machine Learning (DBML), ICDE Workshops},
  year = {2024},
  selected={false},
  bibtex_show={true},
  preview={icde_2024.png},
  pdf={https://www.wis.ewi.tudelft.nl/assets/files/dbml2024/DBML24_paper_11.pdf},  
  abstract={Addressing data quality issues is a challenging task due to the labor-intensive nature of manual data cleaning processes and the inadequacy of automated tools that lack effective repair strategies. In this paper, we introduce ReClean, a novel automated data-cleaning method, dedicated to ML pipelines, that employs reinforcement learning (RL) to optimize data-cleaning tasks. ReClean treats data cleaning as a sequential decision process, where RL agents learn to choose optimal data repai operations that improve ML model convergence and predictive performance. Our extensive experimental evaluation shows that ReClean surpasses existing baseline methods, successfully determining and applying data repair tools to enhance downstream predictive tasks automatically and without supervision},
}

@INPROCEEDINGS{CNA24, 
author={Tobias Clement and  Hung Nguyen and Mohamed Abdelaal}, 
booktitle={IEEE International Conference on Consumer Electronics  (ICCE 2024)}, 
title={XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection},
year={2024},
note={Best Presentation Award},
month={1},
selected={false},
bibtex_show={true},
pdf={https://arxiv.org/pdf/2401.09900},
preview={icce_2024.png},
abstract={Visual quality inspection systems, crucial in sectors like manufacturing and logistics, employ computer vision and machine learning for precise, rapid defect detection. However, their unexplained nature can hinder trust, error identification, and system improvement. This paper presents a framework to bolster visual quality inspection by using CAM-based explanations to refine semantic segmentation models. Our approach consists of 1) Model Training, 2) XAI-based Model Explanation, 3) XAI Evaluation, and 4) Annotation Augmentation for Model Enhancement, informed by explanations and expert insights. Evaluations show XAI-enhanced models surpass original DeepLabv3-ResNet101 models, especially in intricate object segmentation},
}

@INPROCEEDINGS{nguyen2024langxai,
  title={LangXAI: Integrating Large Vision Models for Generating Textual Explanations to Enhance Explainability in Visual Perception Tasks [Demo]},
  author={Nguyen, Truong Thanh Hung and Clement, Tobias and Nguyen, Phuc Truong Loc and Kemmerzell, Nils and Truong, Van Binh and Nguyen, Vo Thanh Khang and Abdelaal, Mohamed and Cao, Hung},
  booktitle={International Joint Conference on Artificial  Intelligence (IJCAI)},
  year={2024},
  month={08},
  selected={false},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2402.12525},
  preview={ijcai_2024.png},
  abstract={LangXAI is a framework that integrates Explainable Artificial Intelligence (XAI) with advanced vision models to generate textual explanations for visual recognition tasks. Despite XAI advancements, an understanding gap persists for end-users with limited domain knowledge in artificial intelligence and computer vision. LangXAI addresses this by furnishing text-based explanations for classification, object detection, and semantic segmentation model outputs to end-users. Preliminary results demonstrate LangXAI’s enhanced plausibility, with high BERTScore across tasks, fostering a more transparent and reliable AI framework on vision tasks for end-users.},
}

@article{MA24,
  title={AI in Manufacturing: Market Analysis and Opportunities},
  author={Mohamed Abdelaal},
  journal={ResearchGate},
  year={2024},
  selected={false},
  bibtex_show={true},
  doi={10.13140/RG.2.2.36200.48643},
  preview={manufacturing.jpg},
  pdf={https://www.researchgate.net/publication/380664557_AI_in_Manufacturing_Market_Analysis_and_Opportunities},
  abstract={In this paper, we explore the transformative impact of Artificial Intelligence (AI) in the manufacturing sector, highlighting its potential to revolutionize industry practices and enhance operational efficiency. We delve into various applications of AI in manufacturing , with a particular emphasis on human-machine interfaces (HMI) and AI-powered milling machines, showcasing how these technologies contribute to more intuitive operations and precision in production processes. Through rigorous market analysis, the paper presents insightful data on AI adoption rates among German manufacturers, comparing these figures with global trends and exploring the specific uses of AI in production, maintenance, customer service, and more. In addition, the paper examines the emerging field of Generative AI and the potential applications of large language models in manufacturing processes. The findings indicate a significant increase in AI adoption from 6% in 2020 to 8% in 2021 among German companies , with a projection of substantial economic impact by 2023. The study also addresses the challenges faced by companies, such as data quality and integration hurdles, providing a balanced view of the opportunities and obstacles in AI implementation.},
}

@INPROCEEDINGS{CNKAS23, 
author={Tobias Clement and  Hung Nguyen and Nils Kemmerzell and Mohamed Abdelaal and Davor Stjelja}, 
booktitle={36th Australasian Joint Conference on Artificial Intelligence (AJCAI2023)}, 
title={Coping with Data Distribution Shifts: XAI-based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction},
  year={2023},
  month={11},
  Note={Best Paper Runner-up Award},
  selected={false},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2402.04982},
  preview={ijcai_2023.png},
  abstract={This paper presents an approach integrating explainable artificial intelligence (XAI) techniques with adaptive learning to enhance energy consumption prediction models, with a focus on handling data distribution shifts. Leveraging SHAP clustering, our method provides interpretable explanations for model predictions and uses these insights to adaptively refine the model, balancing model complexity with predictive performance. We introduce a three-stage process: (1) obtaining SHAP values to explain model predictions, (2) clustering SHAP values to identify distinct patterns and outliers, and (3) refining the model based on the derived SHAP clustering characteristics. Our approach mitigates overfitting and ensures robustness in handling data distribution shifts. We evaluate our method on a comprehensive dataset comprising energy consumption records of buildings, as well as two additional datasets to assess the transferability of our approach to other domains, regression, and classification problems. Our experiments demonstrate the effectiveness of our approach in both task types, resulting in improved predictive performance and interpretable model explanations},}

@INPROCEEDINGS{AKSS22, 
author={Mohamed Abdelaal and Tim Ktitarev and Daniel Staedtler and Harald Schoening}, 
booktitle={27th International Conference on Extending Database Technology (EDBT)}, 
title={SAGED: Meta learning-powered Error Detection Technique for Tabular Data},
  year={2024},
  month={3},
pdf={https://openproceedings.org/2024/conf/edbt/paper-95.pdf},
selected={true},
bibtex_show={true},
preview={edbt_2024.png},
abstract={Numerous automated error detection tools for tabular data have been introduced. Nevertheless, these tools suffer from several shortcomings, encompassing the necessity for domain-specific expertise and substantial time requirements. To address these shortcomings, we introduce a novel error detection tool, denoted as SAGED, which leverage meta-learning principles. Specifically, SAGED exploits an ensemble of pre-trained models derived from historical datasets to facilitate error detection in new data with limited labeled instances. The method consists of two key phases: knowledge extraction and error detection. In the knowledge extraction phase, ML models are trained to distinguish erroneous instances within historical datasets, thereby accumulating valuable insights. In the error detection phase, pretrained base models, chosen through rigorous matching, generate a comprehensive feature vector based on predictions, facilitating the role of a meta-classifier in pinpointing errors efficiently. As a proof of concept, we conduct a comparative study of SAGED against ten state-of-the-art error detection tools, employing a set of 14 real-world datasets. The findings reveal the superior performance of SAGED in error detection tasks, with limited user intervention. SAGED’s promising results demonstrate its effectiveness and efficiency in real-world scenarios.},
}

@INPROCEEDINGS{GBA23, 
author={Daniel Del Gaudio and Fabian Biester and Mohamed Abdelaal}, 
booktitle={1st workshop on Knowledge Base Construction from Pre-Trained Language Models (KBC-LM)}, 
title={Enhancing Knowledge Base Construction from Pre-trained Language Models using Prompt Ensembles},
year={2023},
month={11},
selected={false},
bibtex_show={true},
pdf={https://lm-kbc.github.io/workshop2023/proceedings/4_Biester.pdf},
preview={iswc_2023.png},
abstract={Large language models such as ChatGPT and Bard manifest a significant step in the are of artificial intelligence. Yet, extracting useful knowledge from such models is still a challenging task. Due to the nature of language models, responses can be inaccurate, biased or even speculative. Predicting accurate object-entities by utilizing language model probing is the goal of the LM-KBC challenge. Our approach focuses on the concept of prompt ensembles. We employ initial baseline prompts to ChatGPT and then refine those prompts to exclude suboptimal ones. After a few shot learning step, we use prompt elicitation to improve the output. We use the Llama2 model with 70 billion parameters for inference. Our evaluation shows that this technique significantly enhances previous methods for knowledge base construction from language models. Our implementation is available on https://github.com/asdfthefourth/lmkbc.},}

@INPROCEEDINGS{GSA23, 
author={Daniel Del Gaudio and Tim Schubert and Mohamed Abdelaal}, 
booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
title={RTClean: Context-aware Tabular Data Cleaning using Real-time OFDs},
year={2023},
month={3},
selected={false},
bibtex_show={true},
pdf={https://arxiv.org/pdf/2302.04726},
preview={percom_2023.jpg},
abstract={Nowadays, machine learning plays a key role in developing plenty of applications, e.g., smart homes, smart medical assistance, and autonomous driving. A major challenge of these applications is preserving high quality of the training and the serving data. Nevertheless, existing data cleaning methods cannot exploit context information. Thus, they usually fail to track shifts in the data distributions or the associated error profiles. To overcome these limitations, we introduce, in this paper, a novel method for automated tabular data cleaning powered by dynamic functional dependency rules extracted from a live context model. As a proof of concept, we create a smart home use case to collect data while preserving the context information. Using two different data sets, our evaluations show that the proposed cleaning method outperforms a set of baseline methods in terms of the detection and repair accuracy.},
}

@article{CKA22,
  title={XAIR: A Systematic Meta-Review of Explainable AI aligned to the Software Development Process},
  author={Tobias Clement and Nils Kemmerzell and Mohamed Abdelaal},
  journal={Machine Learning and Knowledge Extraction, special issue on Advances in Explainable Artificial Intelligence (XAI)},
  year={2022},
  preview={xair.jpg},
  selected={false},
  bibtex_show={true},
  pdf={https://www.mdpi.com/2504-4990/5/1/6},
  abstract={Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.},
}

@INPROCEEDINGS{AHS22, 
author={Mohamed Abdelaal and Christian Hammacher and Harald Schoening}, 
booktitle={26th International Conference on Extending Database Technology (EDBT)}, 
title={REIN: Comprehensive Benchmark Framework for Data Cleaning in ML Pipelines},
  year={2023},
  month={3},
  selected={true},
  bibtex_show={true},
  pdf={https://openproceedings.org/2023/conf/edbt/3-paper-49.pdf},
  abstract={Nowadays, machine learning (ML) plays a vital role in many aspects of our daily life. In essence, building well-performing ML applications requires the provision of high-quality data throughout the entire life-cycle of such applications. Nevertheless, most of the real-world tabular data suffer from different types of discrepancies, such as missing values, outliers, duplicates, pattern violation, and inconsistencies. Such discrepancies typically emerge while collecting, transferring, storing, and/or integrating the data. To deal with these discrepancies, numerous data cleaning methods have been introduced. However, the majority of such methods broadly overlook the requirements imposed by downstream ML models. As a result, the potential of utilizing these data cleaning methods in ML pipelines is predominantly unrevealed. In this work, we introduce a comprehensive benchmark, called REIN, to thoroughly investigate the impact of data cleaning methods on various ML models. Through the benchmark, we provide answers to important research questions, e.g., where and whether data cleaning is a necessary step in ML pipelines. To this end, the benchmark examines 38 simple and advanced error detection and repair methods. To evaluate these methods, we utilized a wide collection of ML models trained on 14 publicly-available datasets covering different domains and encompassing realistic as well as synthetic error profiles.},
  preview={edbt_2023.png},}

@INPROCEEDINGS{AK23, 
author={Mohamed Abdelaal and Rashmi Koparde and Harald Schoening}, 
  booktitle={Proceedings of the Sixth International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (SIGMOD Workshops)},
  pages={1--11},
  title={AutoCure: Automated Data Curation Framework for ML Pipelines}, 
  year={2023},
  month={4},
  selected={false},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2304.13636},
  preview={aidm_2023.jpg},
  abstract={In this paper, we present AutoCure, a novel and configuration-free data curation pipeline that improves the quality of tabular data. Unlike traditional data curation methods, AutoCure synthetically enhances the density of the clean data fraction through an adaptive ensemble-based error detection method and a data augmentation module. In practice, AutoCure can be integrated with open source tools, e.g., Auto-sklearn, H2O, and TPOT, to promote the democratization of machine learning. As a proof of concept, we provide a comparative evaluation of AutoCure against 28 combinations of traditional data curation tools, demonstrating superior performance and predictive accuracy without user intervention. Our evaluation shows that AutoCure is an effective approach to automating data preparation and improving the accuracy of machine learning models.},
  }

@article{hilprecht2022diffml,
  title={DiffML: End-to-end Differentiable ML Pipelines},
  author={Hilprecht, Benjamin and Hammacher, Christian and Reis, Eduardo and Abdelaal, Mohamed and Binnig, Carsten},
  journal={DEEM '23: Proceedings of the Seventh Workshop on Data Management for End-to-End Machine Learning (SIGMOD Workshops)},
  year={2023},
  pages={1-7},
  number={7},
  preview={deem_2023.jpg},
  selected={false},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2207.01269},
  doi={https://doi.org/10.1145/3595360.3595857},  
  note={Best Paper Runner-up Award},
  abstract={In this paper, we present our vision of differentiable ML pipelines called DiffML to automate the construction of ML pipelines in an end-to-end fashion. The idea is that DiffML allows to jointly train not just the ML model itself but also the entire pipeline including data preprocessing steps, e.g., data cleaning, feature selection, etc. Our core idea is to formulate all pipeline steps in a differentiable way such that the entire pipeline can be trained using backpropagation. However, this is a non-trivial problem and opens up many new research questions. To show the feasibility of this direction, we demonstrate initial ideas and a general principle of how typical preprocessing steps such as data cleaning, feature selection and dataset selection can be formulated as differentiable programs and jointly learned with the ML model. Moreover, we discuss a research roadmap and core challenges that have to be systematically tackled to enable fully differentiable ML pipelines.},
}

@PATENT{MA23b, 
author={Mohamed Abdelaal and Samuel Lokadja and Arne Kreuz}, 
title={ML-Oriented Interactive Tabular Data Quality Display Systems and Methods}, 
  year={2024},
  note={Submitted to the U.S. patent office},
  month={05},
  selected={false},
  bibtex_show={true},
  preview={patent_pending.jpg},
  }

@PATENT{MA23a, 
author={Mohamed Abdelaal}, 
title={Systems and/or Methods for Reinforced Data Cleaning and Learning in Machine Learning Inclusive Computing Environments}, 
  year={2023},
  note={Submitted to the U.S. patent office},
  month={4},
  selected={false},
  bibtex_show={true},
  preview={patent_pending.jpg},
  }

@PATENT{MA22, 
author={Mohamed Abdelaal}, 
title={Automated Data Preparation Method for ML Pipelines}, 
  year={2022},
  note={Submitted to the U.S. patent office},
  month={8},
  selected={false},
  bibtex_show={true},
  pdf={https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/20240070465},
  preview={patent_pending.jpg},
  }

@PATENT{MA21, 
author={Mohamed Abdelaal}, 
title={Meta Learning-Based Systems for Error Detection in Structured Data}, 
  year={2021},
  note={Submitted to the U.S. patent office},
  month={12},
  selected={false},
  bibtex_show={true},
  pdf={https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/20230205740},
  preview={patent_pending.jpg},
  }

@INPROCEEDINGS{TAW20, 
author={Milan Tepic and Mohamed Abdelaal and Marc Weber and Kurt Rothermel}, 
booktitle={The IEEE 26th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)}, 
title={AutoSec: Multideimensional Timing-Based Anomaly Detection for Automotive Cybersecurity}, 
year={2020},
selected={false},
bibtex_show={true},
pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2020-36/INPROC-2020-36.pdf},
preview={rtsca_2020.jpg},
month={8},
abstract={Nowadays, autonomous driving and driver assistance applications are being developed at an accelerated pace. This rapid growth is primarily driven by the potential of such smart applications to significantly improve safety on public roads and offer new possibilities for modern transportation concepts. Such indispensable applications typically require wireless connectivity between the vehicles and their surroundings, i.e. roadside infrastructure and cloud services. Nevertheless, such connectivity to external networks exposes the internal systems of individual vehicles to threats from remotely-launched attacks. In this realm, it is highly crucial to identify any misbehavior of the software components which might occur owing to either these threats or even software/hardware malfunctioning. In this paper, we introduce AutoSec, a host-based anomaly detection algorithm which relies on observing four timing parameters of the executed software components to accurately detect malicious behavior on the operating system level. To this end, AutoSec formulates the task of detecting anomalistic executions as a clustering problem. Specifically, AutoSec devises a hybrid clustering algorithm for grouping a set of collected timing traces resulted from executing the legitimate code. During the runtime, AutoSec simply classifies a certain execution as an anomaly, if its timing parameters are distant enough from the boundaries of the predefined clusters. To show the effectiveness of AutoSec, we collected timing traces from a testbed composed of a set of real and virtual control units communicating over a CAN bus. We show that using our proposed AutoSec, compared to baseline methods, we can identify up to 21% less false positives and 18% less false negatives.},}
  
@inproceedings{AKD20,
author = {Abdelaal, Mohamed and Karadeniz, Mustafa and D\"urr, Frank and Rothermel, Kurt},
title = {liteNDN: QoS-Aware Packet Forwarding and Caching for Named Data Networks},
booktitle = {CCNC'20: 17th IEEE Annual Consumer Communications \& Networking Conference},
year={2020},
month={01},
selected={false},
bibtex_show={true},
pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2020-01/INPROC-2020-01.pdf},
preview={ccnc_2020.png},
abstract={Recently, named data networking (NDN) has been introduced to connect the world of computing devices via naming data instead of their containers. Through this strategic change, NDN brings several new features to network communication, including in-network caching, multipath forwarding, built-in multicast, and data security. Despite these unique features of NDN networking, there exist plenty of opportunities for continuing developments, especially with packet forwarding and caching. In this context, we introduce liteNDN, a novel forwarding and caching strategy for NDN networks. liteNDN comprises a cooperative forwarding strategy through which NDN routers share their knowledge, i.e. data names and interfaces, to optimize their packet forwarding decisions. Subsequently, liteNDN leverages that knowledge to estimate the probability of each downstream path to swiftly retrieve the requested data. Additionally, liteNDN exploits heuristics, such as routing costs and data significance, to make proper decisions about caching normal as well as segmented packets. The proposed approach has been extensively evaluated in terms of the data retrieval latency, network utilization, and the cache hit rate. The results showed that liteNDN, compared to conventional NDN forwarding and caching strategies, achieves much less latency while reducing the unnecessary traffic and caching activities.},
} 

@inproceedings{ADA19,
 author = {Abdelaal, Mohamed and Dandy, Mochamed and Amr, Marwan and Frank D\"urr and Kurt Rothermel},
 title = {GaaS: Adaptive Generic Gateway Design for IoT Applications},
 booktitle = {2019 IEEE International Conference on Mobile Adhoc and Sensor Systems (MASS'19)},
 year={2019},
 pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2019-27/INPROC-2019-27.pdf},
 month={11},
 selected={false},
 bibtex_show={true},
 preview={gaas.png},
 abstract={Internet of Things (IoT) is expanding at a rapid rate where it allows for virtually endless opportunities and connections to take place. In general, IoT opens the door to a myriad of applications but also to many challenges. One of the major challenges is how to efficiently retrieve the sensory data from “resources-limited” IoT devices. Such devices typically have a restricted energy budget, which broadly hinders their direct connection to the Internet. In this realm, modern mobile devices, e.g. smartphones, tablets, smartwatches, have been harnessed to bridge between the low-power IoT devices and the Internet. However, the current vision which mainly relies on designing siloed gateways, i.e. a separate gateway/App for each IoT device, is certainly impractical, especially with the rapid growth in the number of IoT devices. Furthermore, energy efficiency of the smart mobile devices hosting the IoT gateways has to be thoroughly considered. To tackle these challenges, we introduce GaaS (Gateway as a Service), a cross-platform gateway architecture for opportunistically retrieving sensory data from the low-power IoT sensors. Through Bluetooth low energy radios, GaaS is capable of simultaneously connecting to several nearby IoT sensors. To this end, we devise two distinct priority-based scheduling algorithms, namely the EP-WSM and FEP-AHP schedulers, which rank the detected IoT sensors, before estimating the connection time for each IoT sensor. The intuition behind ranking the IoT sensors is to improve the data retrieval rate from these sensors together with reducing the energy overhead on the mobile devices. Additionally, GaaS encompasses a self-adaptive engine to automatically balance the trade-off between energy efficiency and data retrieval rate through switching between schedulers according to the runtime dynamics. To demonstrate the effectiveness of GaaS, we implemented an IoT testbed to evaluate the energy consumption, the latency, and the data retrieval rate. The results show that using GaaS, compared to siloed gateways, we can identify up to 18% savings in the consumed energy while requiring much less data retrieval time.},
}

@article{ASD19, 
author={Abdelaal, Mohamed and Sekar, Suriya and D\"{u}rr, Frank and Rothermel, Kurt and Becker, Susanne and Fritsch, Dieter}, 
journal={ACM Transactions on Internet of Things (ACM TIOT)}, 
title={MapSense: Grammar-Supported Inference of Indoor Objects from Crowd-Sourced 3D Point Clouds}, 
year={2020}, 
selected={false},
bibtex_show={true},
month={1},
volume={1},
number={1},
preview={tiot.jpg},
pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/ART-2020-03/ART-2020-03.pdf},
abstract={In this paper, we introduce the MapSense approach that automatically derives indoor models from 3D point clouds collected by individuals using mobile devices, such as Google Tango, Apple ARKit, and Microsoft HoloLens. To this end, MapSense leverages several computer vision and machine learning algorithms for precisely inferring the structural objects. In MapSense, we mainly focus on improving the modeling accuracy through adopting formal grammars which encode design-time knowledge, i.e. structural information about the building. In addition to modeling accuracy, MapSense considers the energy overhead on the mobile devices via developing a probabilistic quality model through which the mobile devices solely upload high-quality point clouds to the crowd-sensing servers. To demonstrate the performance of MapSense, we implemented a crowdsensing Android App to collect 3D point clouds from two different buildings by six volunteers. The results showed that MapSense can accurately infer the various structural objects together with drastically reducing the energy overhead on the mobile devices.},
}

@INPROCEEDINGS{KAD18, 
author={K\"{a}ssinger, Johannes and Abdelaal, Mohamed and D\"{u}rr, Frank and Rothermel, Kurt}, 
booktitle={2018 IEEE International Conference on Mobile Adhoc and Sensor Systems}, 
title={GreenMap: Approximated Filtering towards Energy-Aware Crowdsensing for Indoor Mapping}, 
year={2018}, 
doi={10.1109/MASS.2018.00069},
pages={451--459},
selected={false},
bibtex_show={true},
pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2018-30/INPROC-2018-30.pdf},
organization={IEEE},
preview={greenmap.png},
month={10},
abstract={In this paper,  we introduce GreenMap, an energy-aware architectural framework for automatically mapping the interior spaces using crowdsensed point clouds with the support of structural information encoded in formal grammars. GreenMap reduces the energy overhead through projecting the point clouds to several filtration steps on the mobile devices. In this context, GreenMap leverages the potential of approximate computing to reduce the computational cost of data filtering while maintaining a satisfactory level of modeling accuracy. To this end, we propose two approximation strategies, namely DyPR and SuFFUSION. To demonstrate the effectiveness of GreenMap, we implemented a crowdsensing Android App to collect 3D point clouds from two different buildings. We show that GreenMap achieves significant energy savings of up to 67.8%, compared to the baseline methods, while generating comparable floor plans.},
}

@article{ARD18,
 author = {Abdelaal, Mohamed and Reichelt, Daniel and D\"{u}rr, Frank and Rothermel, Kurt and Runceanu, Lavinia and Becker, Susanne and Fritsch, Dieter},
 title = {ComNSense: Grammar-Driven Crowd-Sourcing of Point Clouds for Automatic Indoor Mapping},
 journal = {Proceedings of ACM Interactive, Mobile, Wearable, and Ubiquitous Technologies (ACM UbiComp 2018)},
 issue_date = {March 2018},
 volume = {2},
 number = {1},
 month = {03},
 year = {2018},
 issn = {2474-9567},
 pages = {1:1--1:26},
 articleno = {1},
 numpages = {26},
 url = {http://doi.acm.org/10.1145/3191733},
 doi = {10.1145/3191733},
 acmid = {3191733},
 publisher = {ACM},
 selected={true},
 bibtex_show={true},
 preview={ubicomp.png},
 address = {New York, NY, USA},
 pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2018-29/INPROC-2018-29.pdf},
 keywords = {Crowd-Sensing, Data Acquisition, Energy Efficiency, Formal Grammars, Point Clouds},
 abstract={Recently, point clouds have been efficiently utilized for medical imaging, modeling urban environments, and indoor modeling. In this realm, several mobile platforms, such as Google Tango and Apple ARKit, have been released leveraging 3D mapping, augmented reality, etc. In modeling applications, these modern mobile devices opened the door for crowd-sourcing point clouds to distribute the overhead of data collection. However, uploading these large points clouds from resources-constrained mobile devices to the back-end servers consumes excessive energy. Accordingly, participation rates in such crowd-sensing systems can be negatively influenced. To tackle this challenge, this paper introduces our ComNSense approach that dramatically reduces the energy consumption of processing and uploading point clouds. To this end, ComNSense reports only a set of extracted geometrical data to the servers. To optimize the geometry extraction, ComNSense leverages formal grammars which encode design-time knowledge, i.e. structural information. To demonstrate the effectiveness of ComNSense, we performed several experiments of collecting point clouds from two different buildings to extract the walls location, as a case study. We also assess the performance of ComNSense relative to a grammar-free method. The results showed a significant reduction of the energy consumption while achieving a comparable detection accuracy.},
}  

@INPROCEEDINGS{AQD17, 
author={Mohamed Abdelaal and Mohammad Qaid and Frank D\"{u}rr and Kurt Rothermel}, 
booktitle={2017 IEEE 36th International Performance Computing and Communications Conference (IPCCC)}, 
title={iSense: Energy-aware Crowd-sensing Framework}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-9},
selected={false},
bibtex_show={true}, 
keywords={data acquisition;mobile handsets;resource allocation;wireless LAN;wireless sensor networks;advanced localization approaches thanks;compressed sensing;crowd-sensing servers;crowd-sensing systems;data acquisition;energy budget;energy consumption;energy costs;energy-aware crowd-sensing framework;iSense;lightweight data collection algorithm;localization data;personal mobile devices;sensory data;two-step localization method;usage patterns;Mobile handsets;Monitoring;Sensors;Servers;Wireless communication;Wireless fidelity;Wireless sensor networks}, 
doi={10.1109/PCCC.2017.8280459}, 
ISSN={},
pdf={https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2017-69/INPROC-2017-69.pdf},
preview={ipccc_2017.png}, 
month={12},
abstract={Recently, crowd-sensing has rapidly been evolved thanks to the technological advancement in personal mobile devices. This emerging technology opens the door for numerous applications to collect sensory data from the crowd. To provide people with a motive for participating in data acquisition, the crowd-sensing systems have to sidestep burdening the resources allocated to the mobile devices, i.e. computing power and energy budget. In this paper, we propose iSense, a novel framework for reducing the energy costs of participating in crowd-sensing. We mainly target the superfluous energy overhead on the mobile devices to sense and report their position information to the back-end servers. To relieve such an overhead, iSense entirely offloads the localization burden to the crowd-sensing servers. In this manner, iSense enables the utilization of advanced localization approaches thanks to the high resources of the crowdsensing servers. To this end, iSense opportunistically exploits the “already-existent” network signaling exchanged frequently between the mobile devices and the WiFi networks or the cellular networks. To collect the localization data, we implement a lightweight data collection algorithm on a set of off-theshelves access points. As a case study, we implement a twostep localization method, including a coarse- and a fine-grained localization. In this regard, compressed sensing is employed to estimate the fine-grained solution. To assess the effectiveness of iSense, we implemented a testbed to evaluate the energy consumption and the localization accuracy with different mobility and usage patterns. The results show that using iSense, compared to some baseline methods, we can identify up to 95% savings in the consumed energy.},
}

@inproceedings{ADR17,
 author = {Mohamed Abdelaal and Frank D\"urr and Kurt Rothermel and Susanne Becker and Dieter Fritsch},
 title = {GraMap: QoS-Aware Indoor Mapping with Grammar Support},
 booktitle = {Proceedings of the  International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
 series = {MOBIQUITOUS '17},
 year = {2017},
 selected={false},
 bibtex_show={true},
 pdf={https://web.archive.org/web/20210715095841id_/https://www2.informatik.uni-stuttgart.de/bibliothek/ftp/ncstrl.ustuttgart_fi/INPROC-2017-58/INPROC-2017-58.pdf}, 
 preview={mobiquitous.jpg},
 abstract={Recently, several approaches have been proposed to automatically model indoor environments. Most of such efforts principally rely on the crowd to sense data such as motion traces, images, and WiFi footprints. However, large datasets are usually required to derive precise indoor models which can negatively affect the energy efficiency of the mobile devices participating in the crowd-sensing system. Furthermore, the aforementioned data types are hardly suitable for deriving 3D indoor models. To overcome these challenges, we propose GraMap, a QoS-aware automatic indoor modeling approach through crowd-sensing 3D point clouds. GraMap exploits a recently-developed sensors fusion mechanism, namely Tango technology, to cooperatively collect point clouds from the crowd. Afterward, a set of backend servers extracts the required geometrical information to derive indoor models. For the sake of improving the energy efficiency of the mobile devices, GraMap performs data quality assurance along with 3D data compression. Specifically, we propose a probabilistic quality model—implemented on the mobile devices—to ensure high-quality of the captured point clouds. In this manner, we conserve energy via sidestepping the repetition of sensing queries due to uploading low-quality point clouds. Nevertheless, the resultant indoor models may still suffer from incompleteness and inaccuracies. Therefore, GraMap leverages formal grammars which encode design-time knowledge, i.e. structural information about the building, to enhance the quality of the derived models. To demonstrate the effectiveness of GraMap, we implemented a crowd-sensing Android App to collect point clouds from volunteers. We show that GraMap derives highly-accurate models while reducing the energy costs of pre-processing and reporting the point clouds.},
} 

@inproceedings{APT15,
  author    = {Mohamed Abdelaal and
               Peilin Zhang and
               Oliver E. Theel},
  title     = {QoS Improvement with Lifetime Planning in Wireless Sensor Networks},
  booktitle = {11th International Conference on Mobile Ad-hoc and Sensor Networks,
               {MSN} 2015, Shenzhen, China, December 16-18, 2015},
  pages     = {8--17},
  year      = {2015},
  url       = {https://doi.org/10.1109/MSN.2015.13},
  doi       = {10.1109/MSN.2015.13},
  timestamp = {Sun, 21 May 2017 00:19:58 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/msn/AbdelaalZT15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={wsn.png},
  selected={false},
 bibtex_show={true},
 pdf={https://www.researchgate.net/publication/300408685_QoS_Improvement_with_Lifetime_Planning_in_Wireless_Sensor_Networks},
 abstract={Energy efficiency is an important goal for Wireless Sensor Network (WSN) designers. However, successful implementations of such networks are highly dependent on the enabling technologies, as well as on the provisioning of Quality of Service(QoS) in the network. In this paper, we propose a novel strategy, referred to as the lifetime planning for achieving best-effort QoS. Simultaneously, an adequate lifetime required to complete the assigned task is reached. The core idea is to sidestep lifetime maximization strategies in which sensor nodes continue functioning even after the fulfillment of the required task. In these cases, we could deliberately bound the operational lifetime to the expected task lifetime. As a result, more energy can be spent throughout the entire task lifetime for enhancing the provided service qualities. An analytical QoS model is engineered to validate the QoS’s “conflicts-free” nature of lifetime planning. The proposed strategy is feasible via the design of QoS boundaries at design-time. During run-time, the controllable parameters are modulated by a proactive adaptation mechanism. To demonstrate the effectiveness of our design, we conduct an intensive performance evaluation using an office monitoring scenario in a cluster-tree WSN topology. The scenario has been designed in the Contiki network simulator Cooja using Tmote sky motes. Furthermore, we examine the profit of adopting our strategy relative to fixed heuristics and blind adaptation.},
}

@inproceedings{VAT15,
  author    = {Vasilisa Bashlovkina and
               Mohamed Abdelaal and
               Oliver E. Theel},
  title     = {FuzzyCAT: {A} lightweight Adaptive Transform for sensor data compression},
  booktitle = {{IEEE} International Conference on Communication, {ICC} 2015, London,
               United Kingdom, June 8-12, 2015, Workshop Proceedings},
  pages     = {2756--2762},
  year      = {2015},
  url       = {https://doi.org/10.1109/ICCW.2015.7247596},
  doi       = {10.1109/ICCW.2015.7247596},
  timestamp = {Thu, 25 May 2017 00:39:21 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icc/BashlovkinaAT15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={icc_2015.jpg},
  pdf={https://www.researchgate.net/publication/308872778_FuzzyCAT_A_lightweight_Adaptive_Transform_for_sensor_data_compression},
  selected={false},
  bibtex_show={true},
  abstract={This paper aims at developing a novel high precision compression method. Based on the previously developed Fuzzy Transform Compression (FTC), we design and implement a modified version of the algorithm, referred to as Fuzzy Com-pression Adaptive Transform (FuzzyCAT). The underlying idea of FuzzyCAT is to adapt the transform parameters to the signal’s curvature inferred from the time derivatives. FuzzyCAT outperforms the original FTC while preserving its favorable qualities like periodicity and resilience to lost packets. It also shows a competitive edge over the Lightweight Temporal Compression(LTC) method. A series of experiments with a network of TelosB sensor nodes revealed that transmission costs of the FuzzyCAT algorithm is much less than that of LTC at the expense of a slight increase in processing power. This makes it an outstanding candidate for data compression in wireless sensor networks.},
}

@INPROCEEDINGS{AMT15, 
author={Mohamed Abdelaal and Peter Mosaad and Oliver Theel}, 
booktitle={2015 IEEE Conference on Wireless Sensors (ICWiSe)}, 
title={liteDTW: A lightweight dynamic time warping for tiny wireless sensing devices}, 
year={2015}, 
pages={34-39}, 
keywords={fuzzy set theory;matrix algebra;wireless sensor networks;DTW algorithm;DTW matrix dimensions;correlation estimation;data filtering;data fusing;data fusion;fuzzy abstraction;hard constraints;intermediate sensor nodes;lightweight dynamic time warping;linear operations;liteDTW;resource allocation;resources taxed sensor nodes;spatio-temporal correlation;tiny wireless sensing devices;wireless sensor networks;Data integration;Heuristic algorithms;Legged locomotion;Pattern matching;Sensors;Time series analysis;Wireless sensor networks;Complexity;Data Fusion;Dynamic Time Warping;Energy Efficiency;Fuzzy Abstraction;Wireless Sensor Networks}, 
doi={10.1109/ICWISE.2015.7380350}, 
month={08},
selected={false},
bibtex_show={true},
preview={icwise.png},
pdf={https://www.researchgate.net/publication/304294107_liteDTW_A_lightweight_dynamic_time_warping_for_tiny_wireless_sensing_devices},
abstract={Wireless sensor networks have been recognized as promising tools to collect relevant, in-situ data for a wide range of application domains. However, such networks suffer from hard constraints including the allocated resources. Hence, current research endeavors strive to minimize the amount of data that has to be transmitted. This is typically achieved via data fusing or sending some nodes to sleep mode whenever their readings exhibit a high degree of spatio/temporal correlation. Accordingly, the degree of correlation can be considered as a metrics for data filtering. The Dynamic time warping (DTW) algorithm is a "natural" candidate for data fusion and correlation estimation at intermediate sensor nodes via matching the various measured readings. However, the DTW algorithm suffers from the excessive computational overhead which is ill-suited for the "resources-taxed" sensor nodes. This work aims at reducing this burden via refining the implementation procedure of the DTW algorithm. The liteDTW is a novel version of the DTW algorithm with linear operations and fuzzy abstraction. The core idea is to reduce the DTW matrix dimensions via shrinking the input patterns. Several simulations and real experiments have been conducted to validate that the liteDTW algorithm excels over the naive one in terms of accuracy, time and space overhead. Moreover, the Cooja simulator of the Contiki OS has been utilized to assess the energy profit of adopting the liteDTW algorithm for data fusion.},
}

@inproceedings{VAT15b,
  author    = {Vasilisa Bashlovkina and
               Mohamed Abdelaal and
               Oliver Theel},
  title     = {FuzzyCAT: a novel procedure for refining the F-transform based sensor
               data compression (Poster)},
  booktitle = {Proceedings of the 14th International Conference on Information Processing in Sensor Networks, {IPSN} 2015, Seattle, WA, USA, April 14-16, 2015},
  pages     = {340--341},
  year      = {2015},
  url       = {http://doi.acm.org/10.1145/2737095.2742921},
  doi       = {10.1145/2737095.2742921},
  timestamp = {Fri, 01 May 2015 10:37:37 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ipsn/BashlovkinaAT15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={cps.jpg},
  bibtex_show={true},
  selected={false},
  pdf={https://www.researchgate.net/publication/380210586_FuzzyCAT_A_Novel_Procedure_for_Refining_the_F-transform_Based_Sensor_Data_Compression},
  abstract={This paper aims at developing a novel compression technique which breaks the "downward spiral" between compression ratio and recovery precision. Based on the previously developed Fuzzy Transform Compression (FTC), we design and implement a modified version of the algorithm, referred to as Fuzzy Compression Adaptive Transform (FuzzyCAT). The crux of FuzzyCAT is to adapt the transform parameters to the signal's curvature inferred from the time derivatives , thus smartly exploiting the trade off between compression ratio and precision. A comparative study with the Lightweight Temporal Compression (LTC) technique revealed that transmission costs of the FuzzyCAT nodes are much less than that of the LTC, which makes it an outstanding candidate for data compression in WSNs.},
}


@inproceedings{AKT15,
  author    = {Mohamed Abdelaal and Christian Kuka and Oliver Theel and Daniela Nicklas},
  title     = {Reliable Virtual Sensing for Wireless Sensor Networks},
  booktitle = {The IEEE 10th International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)},
  year      = {2015},
  month     = {4},
  address   = {Singapore},
  page = {1--7},
  timestamp = {2015.04.07},
  preview={issnip.jpg},
  bibtex_show={true},
  selected={false},
  abstract={Several 'energy-hungry' sensors such as gas detectors, radar, and cameras have excessive energy dissipation. Virtual sensing is a technique which 'breaks the downward spiral' between energy expenditure and events-miss probabilities. The idea is to deactivate main sensors and utilize a set of energy-friendly HW & SW components instead. However, reliability of such systems composed of virtual and real sensors should be as high as possible. In this article, a novel approach is proposed to improve the virtual sensing reliability. An ontology on sensor-environment relationships is utilized to automatically generate rules before deployment to switch between real and virtual sensors. We illustrate the general approach by a case study: we show how reliable virtual sensing reduces the energy consumption and event-miss probabilities of object tracking applications. Seismic sensors and a dynamic time-warping algorithm shape the virtual object tracking sensor. We validate the precision of such virtual sensors over several experiments. A series of experiments with a network of TelosB sensor nodes show that virtual sensors have much less energy consumption than a Doppler μ-radar (main) sensor. Finally, we evaluate event-miss probabilities and lifetime extension by using the WSNet simulator.},
  pdf={https://www.researchgate.net/publication/281769902_Reliable_virtual_sensing_for_wireless_sensor_networks},
}

@inproceedings{A15,
  author    = {Mohamed Abdelaal},
  title     = {Fuzzy Compression Refinement via Curvature Tracking},
  booktitle = {Frontiers of Formal Methods},
  year      = {2015},
  month     = {2},
  address   = {Aachen, Germany},
  pages       = {31--35},
  bibtex_show={true},
  selected={false},
  pdf={http://sunsite.informatik.rwth-aachen.de/Publications/AIB/2015/2015-06.pdf},
  timestamp = {2015.03.25},
  preview={ffm.png},
  abstract={In this paper, we aim at developing a unique compression technique which “breaks the downward spiral” between compression ratio and data fidelity. The recently-developed Fuzzy Transform is exploited as a sensor data compressor, called Fuzzy Transform Compression (FTC). Based on contrasting FTC to other compressors, we design and implement a modified version of the FTC algorithm, referred to as FuzzyCAT–Fuzzy Compression: Adaptive Transform. FuzzyCAT adapts the transform parameters in accordance with the signal curvature, which could be inferred from the signal derivatives, to accomplish the optimal balance between compression ratio and precision. Generally, FuzzyCAT provides the users/apps with full control to prioritize either compression ratio or precision according to the significance. FuzzyCAT considerably outperforms the original FTC, whereas preserving its favorable qualities like periodicity and resilience to lost packets. Moreover, a full appraisal depicts the FuzzyCAT eclipses over the LTC at compression ratios above 75. A series of experiments with a network of TelosB sensor nodes revealed that transmission costs of the FuzzyCAT algorithm is 96% less than that of the LTC at the expense of 10.28% increase of processing activities, which makes it an outstanding candidate for data compression in WSN.},
}

@inproceedings{A15b,
  author    = {Mohamed Abdelaal},
  title     = {Distributed Techniques for Energy Conservation in Wireless Sensor Networks},
  booktitle = {Doctoral Consortium in conjunction with the 4th International Conference on Sensor Networks (SENSORNETS)},
  year      = {2015},
  month     = {2},
  address   = {Angers, France},
	pages     = {9--20},
  bibtex_show={true},
  selected={false},
  timestamp = {2015.02.13},
  preview={wsn.png},
  abstract={The PhD program has commenced on December 2012 for three years where the graduation is expected to be in 2016. The main theme of this work is to improve the energy efficiency of Wireless Sensor Networks (WSNs). The thesis has multiple approaches tackling the main sources of energy consumption in WSNs. These approaches are classified into three main roots: ”‘Energy-cheap”’ data aggregation, Hardware optimization and Predictive self-adaptation WSNs. Currently, we have already achieved a reasonable progress as can be seen below.},
  pdf={https://www.researchgate.net/publication/380210832_Distributed_Techniques_for_Energy_Conservation_in_Wireless_Sensor_Networks},
}


@inproceedings{A14,
  author    = {Mohamed Abdelaal},
  title     = {Design and Analysis of Power Conservation Techniques for Wireless Sensor Networks},
  booktitle = {Doctoral Colloquium in conjunction with The 12th ACM Conference on Embedded Networked Sensor Systems (SenSys 2014)},
  year      = {2014},
  month     = {11},
  bibtex_show={true},
  selected={false},
  address   = {Memphis, TN, USA},
  timestamp = {2014.11.12},
  preview={wsn.png},
  abstract={The crux behind this work is to extend the lifetime expectancy of wireless sensor networks (WSNs). In particular, we target exploiting the trade-off between reducing certain quality-of-service (QoS) measures to a degree still tolerable by the application (such as, for example, precision and latency) and maximizing the application's lifetime. For satisfying these objectives, the following sequential steps are addressed. At the outset, an elaborated survey is sketched to aggregate the diverse endeavours in the same context. This survey paves the way for identifying the weak points to be tackled. Basically, we aim at attacking the non-optimal configurations in the hardware, software and network operations that raise the energy consumption. For instance, data compression could alleviate the burden of superfluous transmissions via breaking the downward spiral between compression ratios and precision. For the sensing board, adopting the concept of virtual sensing would minimize duty cycles of the "energy-hungry" sensors. For the radio communication, less energy could be dissipated whenever slashing the operating frequency is viable. Two approaches here can be addressed thorough a careful design of the so-called undersampling receivers, and deliberately activating a subconscious mode midst idle times. From the network scope, current MAC protocols are still non-optimal, hence we reckon a combination of CDMA and RF harvester-based waking up receivers could be an excellent candidate for freely accessing the medium whenever entailed. These proposed techniques are evaluated on a suite of WSN sample applications.},
  pdf={https://www.researchgate.net/publication/380210837_Design_and_Analysis_of_Power_Conservation_Techniques_for_Wireless_Sensor_Networks},
}


@inproceedings{AT14,
  author    = {Mohamed Abdelaal and
               Oliver Theel},
  title     = {Recent energy-preservation endeavours for longlife wireless sensor
               networks: {A} concise survey},
  booktitle = {Eleventh International Conference on Wireless and Optical Communications
               Networks, {WOCN} 2014, Vijayawada, Guntur District, Andhra Pradesh,
               India, September 11-13, 2014},
  pages     = {1-7},
  year      = {2014},
  bibtex_show={true},
  selected={false},
  url       = {http://dx.doi.org/10.1109/WOCN.2014.6923052},
  timestamp = {Wed, 05 Nov 2014 19:19:10 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/wocn/AbdelaalT14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  note = {An extension of the article: Power Management in Wireless Sensor Networks: Challenges and Solutions},
  timestamp = {2014.09.11},
  preview={wsn.png},
  abstract={Energy consumption remains the dominant limitation in most sensor networks. An outsized and growing body of literature has investigated the energy-efficiency problem. In general, energy is afforded either through preserving the already allocated energy sources such as batteries or super-capacitors; or through harvesting energy from the environment; or by utilizing both approaches. In this paper, we highlight the recent research efforts for saving the allocated energy. A unique taxonomy of energy-saving techniques dedicated to sensor networks is provided. Therefore, this paper represents an excellent source for new researchers in this field. Moreover, we present our recent developed approaches within the same context including exploiting the concepts of virtual detection and Fuzzy transform for optimizing the power consumed by sensing and radio communication units, respectively.},
  pdf={https://www.researchgate.net/publication/287314503_Recent_energy-preservation_endeavours_for_longlife_wireless_sensor_networks_A_concise_survey},
}


@inproceedings{AYF14, 
author={Mohamed Abdelaal and Gao Yang and Martin Fr\"anzle and Oliver Theel}, 
booktitle={2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)}, 
title={EAVS: Energy Aware Virtual Sensing for Wireless Sensor Networks}, 
year={2014}, 
month={4}, 
pages = {1--6},
keywords={Wireless Sensor Networks; Energy Ef?ciency; Virtual Sensing; Gas Leak Detection; Fuzzy Logic; Probabilistic Model Checking}, 
isbn={978-1-4799-2843-9},
  timestamp = {2014.04.17},
preview={issnip.jpg},
bibtex_show={true},
selected={false},
pdf={https://www.researchgate.net/publication/262731409_EAVS_Energy_Aware_Virtual_Sensing_for_Wireless_Sensor_Networks},
abstract={In order to extend the operational span of wireless sensor networks, we propose to trade energy consumption for average response time by extending the deactivation periods of sensors with a particularly high energy consumption. To compensate for the temporal inavailability of these sensors, alternative, low-power hybrid sensors generate estimates on the probabilities of the occurrence of interesting events, waking up the corresponding main sensor when detection probability justiﬁes it. We demonstrate the principle on a case study of gas detection and analyze its efﬁciency formally using probabilistic model checking, which is able to compute probabilistic quantiﬁed properties pertaining to energy consumption, lifetime expectancy, and response time. The preliminary results conﬁrm signiﬁcant savings in energy consumption while retaining an acceptable average response time.},
}


@inproceedings{AT13, 
author={Mohamed Abdelaal and Oliver Theel}, 
booktitle={2013 IEEE Conference on Wireless Sensor (ICWISE)}, 
title={An efficient and adaptive data compression technique for energy conservation in wireless sensor networks}, 
year={2013}, 
month={12}, 
pages={124-129}, 
keywords={data compression;energy conservation;fuzzy set theory;power consumption;wireless sensor networks;adaptive data compression technique;compression ratios;compression technique;cost minimization;energy conservation;fuzzy transform;local adaptive data compression;power consumption;radio communication;twisted shielded-pair wire connection;wired sensing systems;wireless sensor networks;Accuracy;Data compression;Temperature sensors;Transforms;Wireless communication;Wireless sensor networks;Compression Technique;Data Conditioning;Fuzzy Transform;Power Conservation;Wireless Sensor Networks}, 
doi={10.1109/ICWISE.2013.6728793},
  timestamp = {2013.12.12},
preview={icwise.png},
bibtex_show={true},
selected={false},
abstract={Wireless sensor networks are superior to wired sensing systems from the economical side provided that the latter require a separate twisted shielded-pair wire connection. Thus, implementation costs for the latter are high. However, wireless sensors have to function for an extensive period of time in order to achieve cost minimization and to successfully complete their particular mission. Therefore, conserving the allocated energy is very important and represents a major dilemma which stands against the wide-spreading of this technology. In this paper, a novel local adaptive data compression based on Fuzzy transform is proposed to minimize the bandwidth, the memory space, and the energy consumed in radio communication. An evaluation of the compression technique is provided. During this evaluation, the proposed technique is examined using real temperature data. The results have shown that the proposed technique can highly reduce the overall power consumption by up to 90 percent. Moreover, a modiﬁcation of the proposed technique is presented which improves the accuracy of the recovered signal even with high compression ratios.},
pdf={https://www.researchgate.net/publication/262731449_An_Efficient_and_Adaptive_Data_Compression_Technique_for_Energy_Conservation_in_Wireless_Sensor_Networks},
}

@inproceedings{AT13b, 
author={Mohamed Abdelaal and Oliver Theel}, 
booktitle={The 2013 International Conference in Centeral Asia on Internet (ICI 2013)}, 
title={Power Management in Wireless Sensor Networks: Challenges and Solutions}, 
year={2013}, 
month={10},  
pages={139--144},
bibtex_show={true},
selected={false},
isbn = {978-1-4799-0558-4},
keywords={Wireless Sensor Networks; Power Management; Data Compression; Taxonomy; Fuzzy Transform},
timestamp = {2013.10.12},
preview={wsn.png},
pdf={https://www.researchgate.net/publication/256294838_Power_Management_in_Wireless_Sensor_NetworksChallenges_and_Solutions},
abstract={This paper provides a novel taxonomy of various energy conservation techniques applied to sensor networks applications in recent times. Moreover, we present our novel approaches in the same context including utilizing software sensors and local adaptive data compression based on Fuzzy Transform.},
}

@inproceedings{ARD12, 
author={Mohamed Abdelaal and Rabie Ramadan and Ahmad Dessouki and Mohamed Abdel{-}meguid}, 
booktitle={The IEEE International Conference on Engineering and Technology (ICET)}, 
title={Energy Saving and Reliable Data Reduction Techniques for Single and Multi-Modal WSNs}, 
year={2012},
month={10},
page={1-8},
bibtex_show={true},
selected={false},
address= {German University in Cairo, Egypt},  
doi={10.1109/ICEngTechnol.2012.6396121},
keywords={Wireless Sensor Networks; Multi-modal Network; Energy Efficiency; Fuzzy Logic},
timestamp = {2012.10.14},
preview={wsn.png},
pdf={https://www.researchgate.net/publication/256294398_Energy_Saving_and_Reliable_Data_Reduction_Techniques_for_Single_and_Multi-Modal_WSNs},
abstract={Wireless Sensor Networks (WSNs) suffer from many limitations such as the computing capabilities, and the allocated bandwidth. However, the limited energy source is the dominant factor where energy starvation occurs due to the large number of messages that need to be transferred through the network. In this paper, we propose new protocols to save the nodes energy as well as prolonging the overall network lifetime. Not like other protocols proposed in the literature, our protocols consider the accuracy/ reliability of the reported data to the sink node. Our first approach considers different types of wireless sensor networks including single and multimodal wireless sensor networks. Our second protocol utilizes the concept of distributed fuzzy logic agents for energy saving in wireless sensor network. Our approaches are extensively tested using simulation as well as real data captured from MIT WSN laboratory. In addition, the paper introduces a WSN prototype based on our data saving approaches. Our conclusion reveals promising results.},
}

@inproceedings{ARD12b, 
author={Mohamed Abdelaal and Rabie Ramadan and Ahmad Dessouki and Mohamed Abdelmeguid}, 
booktitle={The CiiT International Journal}, 
title={Reliable Data Reduction Approaches in WSNs: Greenhouse Plant Disease Detection as a Case Study},
year=2012,
bibtex_show={true},
selected={false},
issue={March 2012},
doi={WC032012003},
url={http://www.ciitresearch.org/wcmarch2012.html},
keywords={Wireless Sensor Network, Data Reduction Technique, Reliability, Multimodal WSN, Fuzzy Logic Controller, WSN Prototype, and Exponential Smoothing Approach},
timestamp = {2012.03.12},
preview={ciit.jpg},
pdf={https://www.researchgate.net/publication/269024799_Reliable_Data_Reduction_Approaches_in_WSNs_Greenhouse_Plant_Disease_Detection_as_a_Case_Study},
abstract={Wireless Sensor Networks have been used in many applications including critical applications such as battle field and health care application. It is also used in many other important applications such as in agriculture. However, such applications require special sensor treatment. Sensors need to be deployed in harsh environment and need to stay alive for long time that could be years not days. In this paper, we propose to utilize wireless sensor networks for greenhouse monitoring against the plant diseases. A multimodal wireless sensor network is used for such purpose. Two different approaches are also proposed for saving the WSN energy including two of the prediction techniques and fuzzy logic controller. In addition, we implemented these approaches in a greenhouse application for plant disease detection. Extensive experiments are conducted to test the performance of the proposed agents.},
}


@inproceedings{ARD11,
  author    = {Mohamed Abdelaal and
               Rabie Ramadan and
               Ahmad Dessouki and
               Mohamed Abdelmeguid},
  title     = {An Efficient Data Reduction Technique for Single and Multi-Modal WSNs},
  booktitle = {Workshop Proceedings of the 7th International Conference on Intelligent
               Environments, {IE} 2011, Nottingham, United Kingdom, July 25-28, 2011},
  pages     = {550--561},
  year      = {2011},
  bibtex_show={true},
  selected={false},
  url       = {http://dx.doi.org/10.3233/978-1-60750-795-6-550},
  doi       = {10.3233/978-1-60750-795-6-550},
  timestamp = {Mon, 10 Sep 2012 16:33:56 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/intenv/Abdel-AllRSA11},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  timestamp = {2011.07.25},
  preview={ie_2011.jpg},
  pdf={https://www.researchgate.net/publication/236233326_An_Efficient_Data_Reduction_Technique_for_Single_and_Multi-Modal_WSNs},
  abstract={Intelligent environments, in general, represent the future evolutionary development step for the real world environment. However, to achieve their aims, an intelligent system is required to collect data from the surrounding environment. Wireless Sensor Networks (WSN) is one of the technologies that extensively used to collect such data. It has been used in many applications such as surveillance, machine failure diagnosis, weather forecast, intelligent environments, intelligent campuses and chemical/biological detection. Nonetheless, their nodes suffer from energy starvation due to the large number of messages need to be transferred through the network. The purpose of this paper is to investigate new approaches for data reduction in single and multimodal WSN. The proposed approaches are based exponential smoothing predictors . At the same time, we believe that such approaches will enhance the reliability of the sensed data. Through large number of experiments, we test our approach through real data as well as through simulation.},
}

% ----------- journal papers ------------------------

@article{RZA17,
  author    = {Jenny R{\"{o}}besaat and
               Peilin Zhang and
               Mohamed Abdelaal and
               Oliver Theel},
  title     = {An Improved {BLE} Indoor Localization with Kalman-Based Fusion: An
               Experimental Study},
  journal   = {Sensors},
  volume    = {17},
  number    = {5},
  pages     = {951},
  year      = {2017},
  bibtex_show={true},
  selected={false},
  url       = {https://doi.org/10.3390/s17050951},
  doi       = {10.3390/s17050951},
  timestamp = {Mon, 26 Jun 2017 16:34:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/sensors/RobesaatZAT17},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={sensors.png},
  pdf={https://www.mdpi.com/1424-8220/17/5/951},
  abstract={Indoor positioning has grasped great attention in recent years. A number of efforts have been exerted to achieve high positioning accuracy. However, there exists no technology that proves its efficacy in various situations. In this paper, we propose a novel positioning method based on fusing trilateration and dead reckoning. We employ Kalman filtering as a position fusion algorithm. Moreover, we adopt an Android device with Bluetooth Low Energy modules as the communication platform to avoid excessive energy consumption and to improve the stability of the received signal strength. To further improve the positioning accuracy, we take the environmental context information into account while generating the position fixes. Extensive experiments in a testbed are conducted to examine the performance of three approaches: trilateration, dead reckoning and the fusion method. Additionally, the influence of the knowledge of the environmental context is also examined. Finally, our proposed fusion method outperforms both trilateration and dead reckoning in terms of accuracy: experimental results show that the Kalman-based fusion, for our settings, achieves a positioning accuracy of less than one meter.},
} 

@article{ZAT18,
  title={Quality of service control in proactive wireless sensor networks via lifetime planning},
  author={Zhang, Peilin and Abdelaal, Mohamed and Theel, Oliver},
  journal={International Journal of Sensor Networks},
  volume={26},
  number={4},
  bibtex_show={true},
  selected={false},
  pages={252--268},
  year={2018},
  publisher={Inderscience Publishers (IEL)},
  preview={ijsn.jpg},
  pdf={https://www.researchgate.net/publication/323767904_Quality_of_service_control_in_proactive_wireless_sensor_networks_via_lifetime_planning},
  abstract={Successful exploitation of the Wireless Sensor networks (WSNs) is intuitively dependent on the enabling technologies as well as on the provision of the application-relevant Quality of Service (QoS) metrics. Current research efforts mostly focus on maximizing the network lifetime without considering the predefined task time. In this article, we firstly provide a survey and a classification of the current state of QoS control methods in WSNs. Subsequently, we propose a novel QoS control method, referred to as lifetime planning. Based on the design-time knowledge, the lifetime planning provides users/applications with best-effort QoS while meeting the time span, required to complete the assigned task. To this end, an “upper ” and a “lower ” QoS boundaries have to be defined for every QoS metric at the design time. During the run time, a self-adaptation framework confines the QoS metrics between their boundaries. Analytically, the lifetime planning outperforms other fixed heuristics and blind adaptation methods. As another proof of concept, we consider an office monitoring scenario with a cluster-tree WSN topology for performance evaluation. The scenario has been designed in the Contiki-OS network simulator, Cooja, using Tmote sky motes. Moreover, a novel QoS model has been engineered to determine the QoS boundaries. Simulation results show that lifetime planning tremendously improves the provided QoS while meeting the task lifetime.},
}


@article{ATK16,
  author    = {Mohamed Abdelaal and
               Oliver Theel and
               Christian Kuka and
               Peilin Zhang and
               Yang Gao and
               Vasilisa Bashlovkina and
               Daniela Nicklas and
               Martin Fr{\"{a}}nzle},
  title     = {Improving Energy Efficiency in QoS-Constrained Wireless Sensor Networks},
  journal   = {{IJDSN}},
  volume    = {12},
  number    = {5},
  pages     = {1576038:1--1576038:28},
  year      = {2016},
  url       = {https://doi.org/10.1155/2016/1576038},
  doi       = {10.1155/2016/1576038},
  timestamp = {Sat, 27 May 2017 14:24:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/ijdsn/AbdelaalTKZGBNF16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={wsn.jpg},
  bibtex_show={true},
  selected={false},
  pdf={https://journals.sagepub.com/doi/full/10.1155/2016/1576038},
  abstract={Energy saving is often achieved via “squeezing” other application-sensitive Quality of Service (QoS) parameters such as delay and throughput. Accordingly, energy-saving methods must consider those QoS parameters. In this paper, we survey the most recent work on energy efficiency in WSNs and we discuss the impacts of these methods on the QoS provided. Moreover, we propose a novel divide-and-conquer procedure to deal with the trade-off between energy consumption and other QoS parameters. The idea is to tackle a certain source of energy consumption to minimize the drawn energy. Subsequently, this energy-saving method is refined to consider other service qualities. To support the correctness of our claim, three energy-saving methods, taking the QoS issues into consideration, are given as examples. The first method exploits a so-called Fuzzy transform for shrinking the wireless traffic with highly precise lossy data compression. In the second method, the sensing module is targeted by employing reliable virtual sensors. Such sensors compensate the unavailability of main energy-hungry sensors during sleep periods. The third method exploits a self-adaptive mechanism to improve the QoS parameters via deliberately reducing the lifetime below the maximum time and exploiting design-time knowledge.},
}


%--------- Theses ---------------------------

@phdthesis{A16a,
  author    = {Mohamed Abdelaal},
  title     = {Enabling Energy-Efficient Wireless Sensing with Improved Service Quality},
  school    = {University of Oldenburg, Germany},
  year      = {2016},
  month     = {12},
  url       = {http://oops.uni-oldenburg.de/2879},
  urn       = {urn:nbn:de:gbv:715-oops-29604},
  timestamp = {Tue, 20 Dec 2016 17:10:19 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/phd/dnb/Abdelaal16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  preview={phd.jpg},
  bibtex_show={true},
  selected={false},
  pdf={http://oops.uni-oldenburg.de/2879},
  abstract={The crux behind this work is to break the "downward spiral" between reducing certain quality-of-service (QoS) measures and extending the wireless sensor network's (WSN) lifetime. For the sake of identifying research challenges and possible gaps, we conduct a comprehensive survey of the state-of-the-art. The reported methods have been classified into node-oriented methods, data-oriented methods, and network-oriented methods. Afterward, the thesis introduces an energy-centric strategy to manipulate the energy-QoS relationship in the light of the relevant context information. It is a design procedure in which the saved energy is dynamically adjusted according to changes in the application and environmental conditions. These adjustments provide the required energy to enhance the service qualities. Due to diversity of WSN applications, we introduce three different methods, based on the energy-centric strategy, namely Fuzzy transform-based data compression, reliable virtual sensing, and lifetime planning.},
}

@MastersThesis{A11a,
  author     =     {Mohamed Abdelaal},
  title     =     {{An Efficient Power Reduction Technique for Wireless Sensor Networks}},
  school     =     {Port Said University},
  address     =     {Egypt},
  month = {11}, 
  type={Master Thesis},
  year     =     {2011},
  preview={master.png},
  doi={10.13140/RG.2.2.24913.54882},
  bibtex_show={true},
  selected={false},
  abstract={This thesis proposes several techniques including predictors and fuzzy logic for minimizing the data sent by different nodes to the base station in order to maximize the WSN lifetime. The thesis also investigates the data reduction in single and multimodal WSN. In addition, it utilizes the concept of exponential smoothing predictors including single and double exponential algorithms as well as the fuzzy logic to provide data reduction and reliability. Moreover, part of our work is dedicated for deploying of WSN inside greenhouses for controlling the environmental conditions.},
  pdf={https://www.researchgate.net/publication/380214799_An_Efficient_Power_Reduction_Technique_for_Wireless_Sensor_Networks},
}

@mastersthesis{A08a,
  document_type     = {Bachelor's Thesis},
  author            = {Mohamed Abdelaal},
  title             = {An Autonomous Mobile Robot for Industrial Operations},
  school            = {Suez Canal University},
  year              = {2008},
  type              = {Bachelor Thesis},
  month             = {05},
  preview={bachelor.png},
  bibtex_show={true},
  selected={false},
  abstract={Mobile robotics is a young field. Its roots include many engineering and science disciplines, from mechanical, electrical and electronics engineering to computer, cognitive and social sciences. Our project focuses on the electrical, electronics and control fields. Our objectives of this project are to build three robots, one robot is manual and two robots are automatic, we participate in the ROBOCON contest by the three robots. We use (PLC) "Programmable Logic Controller" technology to perform Robot operations as it is versatile and reliable device and can be programmed to perform the necessary required operations. Consequently, it is used in wide range of modern industries applications. Also, implement navigation system by using Line tracking technique where Robot can track a line to reach its target, that's can be achieved by optical sensors. it can be shared in industrial operations as it can be programmed to perform many functions like as handling goods and entering dangerous zones that contain harmful materials. We participated in MIE (Made in Egypt) 2008 competition which aims to link the education with industry. Also, we represent our university in ROBOCON EGYPT 2008 contest which develop the creativity and innovation skills. We must mention that our project provide robotics technology in Egypt which become the basic of all modern industries.},
  pdf={https://www.researchgate.net/publication/380262969_An_Autonomous_Mobile_Robot_for_Industrial_Operations},
}
